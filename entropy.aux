\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{niedermeyer_electroencephalography:_2005}
\citation{niedermeyer_electroencephalography:_2005}
\citation{rivet_xdawn_2009}
\citation{wang_enhancing_2006}
\citation{tomioka_logistic_2007}
\citation{johannes_designing_1999}
\citation{kalunga_ssvep_2013}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{barachant_multiclass_2012}
\citation{moakher_differential_2005}
\citation{arsigny_geometric_2007}
\citation{amari_-divergence_2009,arsigny_geometric_2007}
\citation{congedo_new_2013}
\citation{kalunga_hybrid_2014}
\@writefile{toc}{\contentsline {section}{\numberline {2}Classification of covariance matrices for SSVEP}{2}{section.2}}
\newlabel{sec:classofcov}{{2}{2}{Classification of covariance matrices for SSVEP}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}fundamentals of classification}{2}{subsection.2.1}}
\newlabel{subsec:fund_class}{{2.1}{2}{fundamentals of classification}{subsection.2.1}{}}
\newlabel{eq:mean_eucl1}{{1}{2}{fundamentals of classification}{equation.2.1}{}}
\newlabel{eq:mean_eucl2}{{2}{2}{fundamentals of classification}{equation.2.2}{}}
\citation{scholkopf_learning_2001}
\citation{scholkopf_learning_2001}
\citation{karcher_riemannian_2014}
\citation{lim_matrix_2012}
\citation{cartan_groupes_1929}
\citation{cartan_groupes_1929}
\newlabel{eq:classif1}{{3}{3}{Classification of covariance matrices for SSVEP}{equation.2.3}{}}
\newlabel{eq:classif2}{{4}{3}{Classification of covariance matrices for SSVEP}{equation.2.4}{}}
\newlabel{eq:classif_gen}{{5}{3}{Classification of covariance matrices for SSVEP}{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Means of Covariance matrices}{3}{subsection.2.2}}
\newlabel{subsec:mean}{{2.2}{3}{Means of Covariance matrices}{subsection.2.2}{}}
\newlabel{eq:mean}{{7}{3}{Means of Covariance matrices}{equation.2.7}{}}
\citation{arsigny_geometric_2007}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Distance and divergence}{4}{subsubsection.2.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Euclidean distance}{4}{subsubsection.2.2.2}}
\newlabel{eq:dist_eucl}{{8}{4}{Euclidean distance}{equation.2.8}{}}
\newlabel{eq:mean_arithmetic}{{9}{4}{Euclidean distance}{equation.2.9}{}}
\newlabel{eq:mean_power}{{10}{4}{Euclidean distance}{equation.2.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Affine Invariant distance}{4}{subsubsection.2.2.3}}
\citation{pennec_riemannian_2006}
\citation{letcher_principal_2004}
\citation{arsigny_geometric_2007}
\newlabel{eq:metric-riemann}{{11}{5}{Affine Invariant distance}{equation.2.11}{}}
\newlabel{eq:dist_air}{{12}{5}{Affine Invariant distance}{equation.2.12}{}}
\newlabel{mean_air}{{13}{5}{Means of Covariance matrices}{equation.2.13}{}}
\newlabel{eq:invar_congr}{{14}{5}{Means of Covariance matrices}{equation.2.14}{}}
\newlabel{eq:invar_invers}{{15}{5}{Means of Covariance matrices}{equation.2.15}{}}
\newlabel{eq:invar_invers2}{{16}{5}{Means of Covariance matrices}{equation.2.16}{}}
\newlabel{eq:invar_mult}{{17}{5}{Means of Covariance matrices}{equation.2.17}{}}
\citation{bregman_relaxation_1967}
\citation{bregman_relaxation_1967}
\citation{dhillon_matrix_2007}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Log-Euclidean}{6}{subsubsection.2.2.4}}
\newlabel{eq:dist_LE}{{18}{6}{Log-Euclidean}{equation.2.18}{}}
\newlabel{eq:mean_LE}{{19}{6}{Log-Euclidean}{equation.2.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Bregman divergences}{6}{subsubsection.2.2.5}}
\newlabel{eq:bregman-div}{{20}{6}{Bregman divergences}{equation.2.20}{}}
\citation{nielsen_sided_2009}
\citation{chebbi_means_2012}
\citation{chebbi_means_2012,dhillon_matrix_2007,cherian_efficient_2011,sra_positive_2016}
\citation{chebbi_means_2012}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Geometry of the Bregman divergence with the seed function $f(z)=\frac  {1}{2}z^\intercal z$. $h(z)$ is a hyperplane tangent to $f(z)$ at $y$. While it accuratly represent $f(y)$, it underestimate $f(x)$. The Bregman divergence measure how much the the representation of $f(x)$ on $h(z)$ \emph  {diverges} from $f(x)$.\relax }}{7}{figure.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bregman-projection}{{1}{7}{Geometry of the Bregman divergence with the seed function $f(z)=\frac {1}{2}z^\intercal z$. $h(z)$ is a hyperplane tangent to $f(z)$ at $y$. While it accuratly represent $f(y)$, it underestimate $f(x)$. The Bregman divergence measure how much the the representation of $f(x)$ on $h(z)$ \emph {diverges} from $f(x)$.\relax }{figure.1}{}}
\newlabel{eq:div-eucl}{{22}{7}{Means of Covariance matrices}{equation.2.22}{}}
\newlabel{eq:div-kl}{{23}{7}{Means of Covariance matrices}{equation.2.23}{}}
\newlabel{eq:div-log-det}{{24}{7}{Means of Covariance matrices}{equation.2.24}{}}
\citation{sra_positive_2016}
\citation{sra_positive_2016}
\citation{sra_positive_2016}
\citation{nielsen_clustering_2014}
\citation{chebbi_means_2012}
\citation{chebbi_means_2012,sra_positive_2016}
\citation{arsigny_geometric_2007}
\citation{fletcher_principal_2004}
\citation{moakher_differential_2005,letcher_principal_2004}
\citation{chebbi_means_2012}
\citation{chebbi_means_2012,kang_composite_2009}
\citation{cherian_efficient_2011}
\citation{sra_positive_2016,cherian_efficient_2011}
\citation{chebbi_means_2012}
\citation{chebbi_means_2012}
\citation{chebbi_means_2012}
\citation{nielsen_matrix_2012,chebbi_means_2012}
\newlabel{eq:div-js}{{25}{8}{Means of Covariance matrices}{equation.2.25}{}}
\newlabel{eq:div-s}{{26}{8}{Means of Covariance matrices}{equation.2.26}{}}
\newlabel{eq:div-alpha}{{27}{8}{Means of Covariance matrices}{equation.2.27}{}}
\newlabel{eq:div-alpha2}{{28}{8}{Means of Covariance matrices}{equation.2.28}{}}
\newlabel{eq:div-log-det-alpha}{{29}{8}{Means of Covariance matrices}{equation.2.29}{}}
\citation{barachant_multiclass_2012}
\citation{congedo_new_2013}
\citation{schafer_shrinkage_2005}
\citation{barachant2013riemannian}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Distances, divergences and means considered in the experimental study.\relax }}{9}{table.1}}
\newlabel{tab:dist}{{1}{9}{Distances, divergences and means considered in the experimental study.\relax }{table.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}Wasserstein}{9}{subsubsection.2.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Minimum Distance to Mean classifier for SSVEP}{9}{subsection.2.3}}
\newlabel{subsec:mdm}{{2.3}{9}{Minimum Distance to Mean classifier for SSVEP}{subsection.2.3}{}}
\newlabel{eq:ext_data}{{30}{9}{Minimum Distance to Mean classifier for SSVEP}{equation.2.30}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Minimum Distance to Mean Classifier\relax }}{9}{algorithm.1}}
\newlabel{alg:mdm}{{1}{9}{Minimum Distance to Mean Classifier\relax }{algorithm.1}{}}
\newlabel{op:class_center}{{3}{9}{Minimum Distance to Mean Classifier\relax }{algorithm.1}{}}
\newlabel{op:decision}{{5}{9}{Minimum Distance to Mean Classifier\relax }{algorithm.1}{}}
\citation{kalunga_hybrid_2014}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Results}{10}{section.3}}
\newlabel{sec:expresults}{{3}{10}{Experimental Results}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}SSVEP Dataset}{10}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Results and Discussion}{10}{subsection.3.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{10}{figure.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{10}{figure.2}}
\newlabel{fig:covmat12}{{2(a)}{10}{Subfigure 2(a)}{subfigure.2.1}{}}
\newlabel{sub@fig:covmat12}{{(a)}{10}{Subfigure 2(a)\relax }{subfigure.2.1}{}}
\newlabel{fig:covmat11}{{2(b)}{10}{Subfigure 2(b)}{subfigure.2.2}{}}
\newlabel{sub@fig:covmat11}{{(b)}{10}{Subfigure 2(b)\relax }{subfigure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Representation of covariance matrices: each image is the covariance matrix mean $\ensuremath  {\mathaccentV {bar}416{\ensuremath  {\Sigma }}}^{(\ensuremath  {k})}$ of the class $\ensuremath  {k}$, for one session of the recording. The diagonal blocks show the covariance in different frequency bands, i.e. 13Hz in the upper-left block, 21Hz in the middle, and 17Hz in the bottom-right. Subjects with highest (a) and lowest (b) BCI performance. \relax }}{10}{figure.2}}
\newlabel{fig:covmat}{{2}{10}{Representation of covariance matrices: each image is the covariance matrix mean $\Pm ^{(\ci )}$ of the class $\ci $, for one session of the recording. The diagonal blocks show the covariance in different frequency bands, i.e. 13Hz in the upper-left block, 21Hz in the middle, and 17Hz in the bottom-right. Subjects with highest (a) and lowest (b) BCI performance. \relax }{figure.2}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{11}{figure.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{11}{figure.3}}
\newlabel{fig:swel}{{3(a)}{11}{Subfigure 3(a)}{subfigure.3.1}{}}
\newlabel{sub@fig:swel}{{(a)}{11}{Subfigure 3(a)\relax }{subfigure.3.1}{}}
\newlabel{fig:alphacross}{{3(b)}{11}{Subfigure 3(b)}{subfigure.3.2}{}}
\newlabel{sub@fig:alphacross}{{(b)}{11}{Subfigure 3(b)\relax }{subfigure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a): Swelling effect of Arithmetic mean shown through log-determinant values. Training trials are taken from the 13Hz class of the subject with the highest BCI performance. Log-determinant values are given for each trial covariance (points), and for means of Table\nobreakspace  {}\ref  {tab:dist} (horizontal lines). (b): Classification accuracy and CPU time, obtained with $\alpha $-divergence for $-1\leqslant \alpha \leqslant 1$.\relax }}{11}{figure.3}}
\newlabel{fig:swel_alpha}{{3}{11}{(a): Swelling effect of Arithmetic mean shown through log-determinant values. Training trials are taken from the 13Hz class of the subject with the highest BCI performance. Log-determinant values are given for each trial covariance (points), and for means of Table~\ref {tab:dist} (horizontal lines). (b): Classification accuracy and CPU time, obtained with $\alpha $-divergence for $-1\leqslant \alpha \leqslant 1$.\relax }{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{11}{section.4}}
\newlabel{sec:conclusion}{{4}{11}{Conclusion}{section.4}{}}
\bibstyle{mdpi}
\bibdata{entropy}
\bibcite{niedermeyer_electroencephalography:_2005}{{1}{2005}{{Niedermeyer and Silva}}{{}}}
\bibcite{rivet_xdawn_2009}{{2}{2009}{{Rivet \em  {et~al.}}}{{Rivet, Souloumiac, Attina, and Gibert}}}
\bibcite{wang_enhancing_2006}{{3}{2006}{{Wang and James}}{{}}}
\bibcite{tomioka_logistic_2007}{{4}{2007}{{Tomioka \em  {et~al.}}}{{Tomioka, Aihara, and M\IeC {\"u}ller}}}
\bibcite{johannes_designing_1999}{{5}{1999}{{Johannes \em  {et~al.}}}{{Johannes, Pfurtscheller, and Flyvbjerg}}}
\bibcite{kalunga_ssvep_2013}{{6}{2013}{{Kalunga \em  {et~al.}}}{{Kalunga, Djouani, Hamam, Chevallier, and Monacelli}}}
\bibcite{barachant_multiclass_2012}{{7}{2012}{{Barachant \em  {et~al.}}}{{Barachant, Bonnet, Congedo, and Jutten}}}
\bibcite{moakher_differential_2005}{{8}{2005}{{Moakher}}{{}}}
\bibcite{arsigny_geometric_2007}{{9}{2007}{{Arsigny \em  {et~al.}}}{{Arsigny, Fillard, Pennec, and Ayache}}}
\bibcite{amari_-divergence_2009}{{10}{2009}{{Amari}}{{}}}
\bibcite{congedo_new_2013}{{11}{2013}{{Congedo \em  {et~al.}}}{{Congedo, Barachant, and Andreev}}}
\bibcite{kalunga_hybrid_2014}{{12}{2014}{{Kalunga \em  {et~al.}}}{{Kalunga, Chevallier, Rabreau, and Monacelli}}}
\bibcite{scholkopf_learning_2001}{{13}{2001}{{Scholkopf and Smola}}{{}}}
\bibcite{karcher_riemannian_2014}{{14}{2014}{{Karcher}}{{}}}
\bibcite{lim_matrix_2012}{{15}{2012}{{Lim and P\IeC {\'a}lfia}}{{}}}
\bibcite{cartan_groupes_1929}{{16}{1929}{{Cartan}}{{}}}
\bibcite{pennec_riemannian_2006}{{17}{2006}{{Pennec \em  {et~al.}}}{{Pennec, Fillard, and Ayache}}}
\bibcite{bregman_relaxation_1967}{{18}{1967}{{Bregman}}{{}}}
\bibcite{dhillon_matrix_2007}{{19}{2007}{{Dhillon and Tropp}}{{}}}
\bibcite{nielsen_sided_2009}{{20}{2009}{{Nielsen and Nock}}{{}}}
\bibcite{chebbi_means_2012}{{21}{2012}{{Chebbi and Moakher}}{{}}}
\bibcite{cherian_efficient_2011}{{22}{2011}{{Cherian \em  {et~al.}}}{{Cherian, Sra, Banerjee, and Papanikolopoulos}}}
\bibcite{sra_positive_2016}{{23}{2016}{{Sra}}{{}}}
\bibcite{nielsen_clustering_2014}{{24}{2014}{{Nielsen \em  {et~al.}}}{{Nielsen, Nock, and Amari}}}
\bibcite{fletcher_principal_2004}{{25}{2004}{{{Fletcher} and Joshi}}{{}}}
\bibcite{kang_composite_2009}{{26}{2009}{{Kang \em  {et~al.}}}{{Kang, Nam, and Choi}}}
\bibcite{nielsen_matrix_2012}{{27}{2012}{{Nielsen and Bhatia}}{{}}}
\bibcite{schafer_shrinkage_2005}{{28}{2005}{{Sch\IeC {\"a}fer and Strimmer}}{{}}}
\newlabel{RF1}{14}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Subject classification accuracies (acc(\%)) and average CPU time (time(s)) elapsed for the classification of a single trial. Classification is performed with MDM using either Euclidean or Riemannian means (see Table\nobreakspace  {}\ref  {tab:dist}).\relax }}{14}{table.caption.1}}
\newlabel{tab:res}{{2}{14}{Subject classification accuracies (acc(\%)) and average CPU time (time(s)) elapsed for the classification of a single trial. Classification is performed with MDM using either Euclidean or Riemannian means (see Table~\ref {tab:dist}).\relax }{table.caption.1}{}}
\newlabel{LastPage}{{}{14}{}{page.14}{}}
\xdef\lastpage@lastpage{14}
\xdef\lastpage@lastpageHy{14}
